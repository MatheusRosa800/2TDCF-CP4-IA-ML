{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Entendendo a geração de próximos tokens, diferenças de modelos e devices + relembrando aula passada\n"
      ],
      "metadata": {
        "id": "ZL_nNqw_ZlwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vendo se temos GPU disponivel\n",
        "\n",
        "# !nvidia-smi <-- não vai funcionar se não tiver GPU\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import transformers\n",
        "\n",
        "torch.cuda.is_available() # retorna Ture se encontrou uma GPU para mandar os jobs\n",
        "\n",
        "# identificando o dispositivo dinamicamente\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print(device)\n"
      ],
      "metadata": {
        "id": "e6YU3xdoZWu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criação do modelo de linguagem Llama"
      ],
      "metadata": {
        "id": "W6dyu3aMZydv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tiny_llama = transformers.pipeline(\n",
        "    task = \"text-generation\",\n",
        "    model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(tiny_llama)\n",
        "print(tiny_llama.model)"
      ],
      "metadata": {
        "id": "0wuzfMvrajHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'today is a beautiful day to'\n",
        "\n",
        "# Maneira mais direta possivel de usar um modelo. Ele vai usar os parametros padrões para gerar a saida\n",
        "output = tiny_llama(prompt)\n",
        "\n",
        "# Se não especificarmos o máximo de novos tokens ele vai gerar ate encontrar um token que sinalisa fim da sentenca.\n",
        "\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVUL4vrubZyC",
        "outputId": "34d400c3-b7e3-442b-92f2-93bf51ac0863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'today is a beautiful day to be alive.\\n\\n(The camera pans out to show the sun shining brightly, the sky turning from blue to pink, and the leaves rustling in the wind.)\\n\\nNarrator: And as we look around, we see the world around us in a new light.\\n\\n(The camera pans out to show the city skyline, the buildings glowing in the sunlight, and the people walking around, smiling and laughing.)\\n\\nNarrator: We see the beauty of the world around us, and we know that we are lucky to be alive.\\n\\n(The camera pans out to show the sun setting behind the mountains, the sky turning from pink to orange, and the stars twinkling in the night sky.)\\n\\nNarrator: And as we watch the sun set, we know that we are witnessing a moment in time that will never be repeated.\\n\\n(The camera pans out to show the sky turning from orange to red, and the sun setting behind the mountains, the sky turning into a beautiful shade of purple.)\\n\\nNarrator: We see the beauty of the world around us, and we know that we are lucky to be alive.\\n\\n(The camera pans out to show the sun setting behind the mountains, the sky turning into a beautiful shade of pink, and the stars twinkling in the night sky.)\\n\\nNarrator: And as we watch the sun set, we know that we are witnessing a moment in time that will never be repeated.\\n\\n(The camera pans out to show the sky turning from pink to purple, and the sun setting behind the mountains, the sky turning into a beautiful shade of orange.)\\n\\nNarrator: We see the beauty of the world around us, and we know that we are lucky to be alive.\\n\\n(The camera pans out to show the sun setting behind the mountains, the sky turning into a beautiful shade of yellow, and the stars twinkling in the night sky.)\\n\\nNarrator: And as we watch the sun set, we know that we are witnessing a moment in time that will never be repeated.\\n\\n(The camera pans out to show the sky turning from yellow to red, and the sun setting behind the mountains, the sky turning into a beautiful shade of red.)\\n\\nNarrator: We see the beauty of the world around us, and we know that we are lucky to be alive.\\n\\n(The camera pans out to show the sky turning into a beautiful shade of purple, and the sun setting behind the mountains, the sky turning into a beautiful shade of blue.)\\n\\nNarrator: And as we watch the sun set, we know that we are witnessing a moment in time that will never be repeated.\\n\\n(The camera pans out to show the sky turning into a beautiful shade of violet, and the sun setting behind the mountains, the sky turning into a beautiful shade of green.)\\n\\nNarrator: We see the beauty of the world around us, and we know that we are lucky to be alive.\\n\\n(The camera pans out to show the sky turning into a beautiful shade of green, and the sun setting behind the mountains, the sky turning into a beautiful shade of brown.)\\n\\nNarrator: And as we watch the sun set, we know that we are witnessing a moment in time that will never be repeated.\\n\\n(The camera pans out to show the sky turning into a beautiful shade of brown, and the sun setting behind the mountains, the sky turning into a beautiful shade of gray.)\\n\\nNarrator: We see the beauty of the world around us, and we know that we are lucky to be alive.\\n\\n(The camera pans out to show the sky turning into a beautiful shade of gray, and the sun setting behind the mountains, the sky turning into a beautiful shade of white.)\\n\\nNarrator: And as we watch the sun set, we know that we are witnessing a moment in time that will never be repeated.\\n\\n(The camera pans out to show the sky turning into a beautiful shade of white, and the sun setting behind the mountains, the sky turning into a beautiful shade of black.)\\n\\nNarrator: We see the beauty of the world around us, and we know that we are lucky to be alive.\\n\\n(The camera pans out to show the sky turning into a beautiful shade of black, and the sun setting behind the mountains, the sky turning into a beautiful shade of gray.)\\n\\nNarrator: And as we watch the sun set, we know that we are witnessing a moment in time that will never be repeated.\\n\\n(The camera pans out to show the sky turning into a beautiful shade of gray, and the sun setting behind the mountains, the sky turning into a beautiful shade of blue.)\\n\\nNarrator: We see the beauty of the world around us, and we know that we are lucky to be alive.\\n\\n(The camera pans out to show the sky turning into a beautiful shade of blue, and the sun setting behind the mountains, the sky turning into a beautiful shade of green.)\\n\\nNarrator: And as we watch the sun set, we know that we are witnessing a moment in time that will never be repeated.\\n\\n(The camera pans out to show the sky turning into a beautiful shade of green, and the sun setting behind the mountains, the sky turning into a beautiful shade of yellow.)\\n\\nNarrator: We see the beauty of the world around us, and we know that we are lucky to be alive.\\n\\n(The camera pans out to show the sky turning into a beautiful shade of yellow, and the sun setting behind the mountains, the sky turning into a beautiful shade of orange.)\\n\\nNarrator: And as we watch the sun set, we know that we are witnessing a moment in time that will never be repeated.\\n\\n(The camera pans out to show the sky turning into a beautiful shade of orange, and the sun setting behind the mountains, the sky turning into a beautiful shade of red.)\\n\\nNarrator: We see the beauty of the world around us, and we know that we are lucky to be alive.\\n\\n(The camera pans out to show the sky turning into a beautiful shade of red, and the sun setting behind the mountains, the sky turning into a beautiful shade of pink.)\\n\\nNarrator: And as we watch the sun set, we know that we are witnessing a moment in time that will never be repeated.\\n\\n(The camera pans out to show the sky turning into a beautiful shade of pink, and the sun setting behind the mountains, the sky turning into a beautiful shade of purple.)\\n\\nNarrator: We see the beauty of the world around us, and we know that we are lucky to be alive.\\n\\n(The camera pans out to show the sky turning into a beautiful shade of purple, and the sun setting behind the mountains, the sky turning into a beautiful shade of blue.)\\n\\nNarrator: And as we watch the sun set, we know that we are witnessing a moment in time that will never be repeated.\\n\\n(The camera pans out to show the sky turning into a beautiful shade of blue, and the sun setting behind the mountains, the sky turning into a beautiful shade of green.)\\n\\nNarrator: We see the beauty of the world around us, and we know that we are lucky to be alive.\\n\\n(The camera pans out to show the sky turning into a beautiful shade of green, and the sun setting behind the mountains, the sky turning into a beautiful shade of brown.)\\n\\nNarrator: And as we watch the sun set, we know that we are witnessing a moment in time that will never be repeated.\\n\\n(The camera pans out to show the sky turning into a beautiful shade of brown, and the sun setting behind the mountains, the sky turning into a beautiful shade of gray.)\\n\\nNarrator: We see the beauty of the world around us, and we know that we are lucky to be alive.\\n\\n(The camera pans out to show the sky turning into a beautiful shade of gray, and the sun setting behind the mountains, the sky turning into a beautiful shade of white.)\\n\\nNarrator: And as we watch the sun set, we know that we are witnessing a moment in time that will never be repeated.\\n\\n(The camera pans out to show the sky turning into a beautiful shade of white, and the sun setting behind the mountains, the sky turning into a beautiful shade of black.)\\n\\nNarrator: We see the beauty of the world around us, and we know that we are lucky to be alive.\\n\\n(The camera pans out to show the sky turning into a beautiful shade of black, and the sun setting behind the mountains, the sky turning into a beautiful shade of gray.)\\n\\nNarrator: And as we watch the sun set, we know that we are witnessing a moment in time that will never be repeated.\\n\\n(The camera pans out to show the sky turning into a beautiful shade of gray, and the sun setting behind the mountains, the sky turning into a beautiful shade of blue.)\\n'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vendo o processo de geracão token by token"
      ],
      "metadata": {
        "id": "vKLPI9-3aBjU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# O que é um Tensor\n",
        "\n",
        "Um tensor é uma estrutura de dados fundamental utilizada em redes neurais e aprendizado de máquina, representando dados multidimensionais de forma eficiente. Pode ser visto como uma generalização de matrizes, que permite representar dados em várias dimensões (escalar, vetor, matriz, etc.).\n",
        "\n",
        "Em frameworks como PyTorch (pt) e TensorFlow (tf), tensores são a base para armazenar e manipular dados de entrada, pesos, saídas e gradientes durante o treinamento e inferência de modelos de machine learning. Eles suportam operações matemáticas complexas que são otimizadas para hardware acelerado, como GPUs.\n",
        "\n",
        "Uma característica importante dos tensores é o método .to(device), que permite mover o tensor para o dispositivo desejado (CPU ou GPU), garantindo que os dados estejam no mesmo dispositivo que o modelo, facilitando a execução eficiente de operações."
      ],
      "metadata": {
        "id": "IA66fbHJaPDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_input_ids = tiny_llama.tokenizer.encode(prompt, return_tensors='pt').input_ids.to(device)\n",
        "\n",
        "# para inspecionar a geração de tokens, precisamos gerar o output com novos parametros\n",
        "\n",
        "output = tiny_llama.model.generate(\n",
        "    prompt_input_ids,\n",
        "    max_new_tokens = 25,\n",
        "    return_dict_in_generate = True, # retorne um dicionario com informacoes da geracao de dados\n",
        "    output_scores = True, # retorne as pontuacoes de cada token gerado\n",
        ")\n",
        "\n",
        "print(output.keys())"
      ],
      "metadata": {
        "id": "Z3KrcsUAdHRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vamos pegar os TRANSITION SCORES (probabildidade da palavra utilizada)\n",
        "\n",
        "transitions = tiny_llama.model.compute_transition_scores(\n",
        "    output.sequences,\n",
        "    output.scores,\n",
        "    normalize_logits=True\n",
        ")"
      ],
      "metadata": {
        "id": "toyMuxfVeZf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ver a sequência de transicão do que foi gerado (ignora o prompt original)\n",
        "\n",
        "tamanho_prompt = len(prompt_input_ids[0])\n",
        "print(tamanho_prompt)\n",
        "\n",
        "# nosso prompt faz parte da resposta gerada\n",
        "print(output.sequences[0][:tamanho_prompt])\n",
        "\n",
        "\n",
        "generated_tokens = output.sequences[0][tamanho_prompt:]\n",
        "print(generated_tokens)\n",
        "\n",
        "print('| token id | score | token str | pro %')\n",
        "for (token, score) in zip(generated_tokens,transitions[0]):\n",
        "    print(token, score.to('cpu').numpy(), tiny_llama.tokenizer.decode(token),np.exp(score.to('cpu').numpy()))"
      ],
      "metadata": {
        "id": "6mDO08K_fTcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vendo o tempo de execução para gerar um prompt\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "output = tiny_llama(prompt, max_new_tokens=100)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(tiny_llama.model)\n",
        "print(f'Tempo de execucao: {end - start:.2f} segundos')\n",
        "print(output)\n",
        "print(output[0]['generated_text'])"
      ],
      "metadata": {
        "id": "fIYToyy-YB3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fazendo com que o modelo lembre da conversa e dos prompts anteriores"
      ],
      "metadata": {
        "id": "7wnnY8cmau9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = \"What day is today?\"\n",
        "prompt2 = \"What day is tomorrow?\"\n",
        "\n",
        "output = tiny_llama(prompt1, max_new_tokens=10)\n",
        "print(output[0]['generated_text'])\n",
        "\n",
        "print(\"-\"*80)\n",
        "\n",
        "output = tiny_llama(prompt2, max_new_tokens=10)\n",
        "print(output[0]['generated_text'])\n",
        "\n",
        "# Ué, o que aconteceu? Alucinou?"
      ],
      "metadata": {
        "id": "XME_Pp0nYDra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# para se lembrar, precisamos alimentar ele com TUDO QUE FOI GERADO ANTERIORMENTE\n",
        "\n",
        "prompt1 = \"What day is today?\"\n",
        "prompt2 = \"What day is tomorrow?\"\n",
        "\n",
        "output = tiny_llama(prompt1, max_new_tokens=10)\n",
        "print(output[0]['generated_text'])\n",
        "\n",
        "print(\"-\"*80)\n",
        "\n",
        "output = tiny_llama(output[0]['generated_text'] + prompt2, max_new_tokens=30)\n",
        "print(output[0]['generated_text'])"
      ],
      "metadata": {
        "id": "QKd6Ev7pYFVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregando outro modelo\n",
        "\n",
        "O código abaixo vai explodir a memória ram (porque já temos o outro modelo carregado nela)."
      ],
      "metadata": {
        "id": "-DWSJ7exbIAP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Novo Modelo: Falcon-7b"
      ],
      "metadata": {
        "id": "dyKFl2O7cKWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Falcon-7B é um modelo de linguagem desenvolvido para entender e gerar texto de maneira semelhante aos modelos GPT, com uma arquitetura e escopo intermediários, voltado para uma ampla gama de aplicações em processamento de linguagem natural. Ele é projetado para oferecer um bom equilíbrio entre desempenho e eficiência, sendo adequado tanto para pesquisa quanto para aplicações em ambientes de produção que podem acomodar modelos de médio porte.\n",
        "\n",
        "Esse modelo é ideal para desenvolvedores e pesquisadores que procuram um modelo poderoso, mas que ainda pode ser gerenciado com recursos computacionais moderados, oferecendo um excelente compromisso entre qualidade e custo operacional.\n",
        "\n",
        "[Model Link](https://huggingface.co/tiiuae/falcon-7b)\n",
        "\n",
        "Características\n",
        "\n",
        "\n",
        "| Setting         | Description        |\n",
        "| --------------- | -----------------  |\n",
        "| Parameters      | 7B                 |\n",
        "| Layers          | 32                 |\n",
        "| Heads           | 48                 |\n",
        "| Query Groups    | 1                  |\n",
        "| Embedding Size  |4544                |\n",
        "| Batch Size      | 4 million tokens   |\n",
        "| Total Tokens    | 1.5 trillion       |\n",
        "| Hardware        | 4 A100-40G GPUs    |\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2J-qeNDMcUuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# deletando e limpando a memória\n",
        "\n",
        "import gc # garbage colector\n",
        "del tiny_llama\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "falcon = transformers.pipeline(\n",
        "     task='text-generation',\n",
        "     model='tiiuae/falcon-7b',\n",
        "     device=device\n",
        " )"
      ],
      "metadata": {
        "id": "tRNqcJUWYGyb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
