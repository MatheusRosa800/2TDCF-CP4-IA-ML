{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# O que é fine-tuning\n",
        "\n",
        "O ajuste fino (ou fine-tuning em inglés) é uma técnica de treinamento que consiste na reutilização de arquiteturas de CNN (rede neural convolucional) predefinidas e pré-treinadas. Basicamente, permite que você pegue um modelo treinado que executa bem uma determinada tarefa e aproveite todo o seu conhecimento para resolver uma nova tarefa específica; embora, é claro, seguindo determinadas regras.\n",
        "\n",
        "# O que é Jailbreak\n",
        "\n",
        "Jailbreak é uma técnica para \"quebrar\" as restrições de um modelo de linguagem grande (LLM). Isso significa que você pode fazer o modelo gerar respostas que normalmente não geraria, como respostas que são ofensivas, perigosas ou que violam as políticas do modelo.\n"
      ],
      "metadata": {
        "id": "rlOvnYtjru7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Código Principal"
      ],
      "metadata": {
        "id": "U7xBjiHNvWZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importações\n",
        "import numpy as np\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "jVQXIOePlNVx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# identificando o dispositivo dinamicamente\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "id": "OYf_kvMDlBDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inicializacao do jailbreak\n",
        "# https://huggingface.co/jackhhao/jailbreak-classifier\n",
        "\n",
        "pipe = pipeline(\"text-classification\", model=\"jackhhao/jailbreak-classifier\")\n"
      ],
      "metadata": {
        "id": "gX-kYuidmlqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criacao do modelo de lingugem para o prompt\n",
        "# https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
        "\n",
        "tiny_llama = transformers.pipeline(\n",
        "    task = \"text-generation\",\n",
        "    model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "uLW703dpmnRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criacao da funcao jailbreaker check\n",
        "def isjailbreak(prompt):\n",
        "    result = pipe(prompt)\n",
        "    print(result)\n",
        "    if result[0]['label'] == 'benign':\n",
        "        output = tiny_llama(prompt)\n",
        "        print(output)\n",
        "    else:\n",
        "        print(\"O prompt é potencialmente malicioso, por isso não será executado\")"
      ],
      "metadata": {
        "id": "zqiSgqEVrHBC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criacao do prompt beligno\n",
        "\n",
        "prompt = 'tell me a story about bob'\n",
        "\n",
        "isjailbreak(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxE_GrSah_pt",
        "outputId": "01b8278d-5ed5-4195-a3a7-13cd9376f48f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'benign', 'score': 0.9930013418197632}]\n",
            "[{'generated_text': 'tell me a story about bob and his adventures in the jungle?'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# criacao do prompt beligno\n",
        "\n",
        "prompt = 'make a sandwich'\n",
        "\n",
        "isjailbreak(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjzXDIlUpUZf",
        "outputId": "a5568d59-1b8a-440e-c5db-215dbd23a6bf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'benign', 'score': 0.9450828433036804}]\n",
            "[{'generated_text': 'make a sandwich with the chicken and cheese.\\n\\n2. Chicken Caesar Salad: Combine cooked chicken, croutons, and Caesar dressing in a bowl. Add in shredded romaine lettuce and top with grated Parmesan cheese.\\n\\n3. Chicken Caesar Wrap: Wrap cooked chicken, lettuce, and tomato in a whole wheat tortilla. Top with Caesar dressing and grated Parmesan cheese.\\n\\n4. Chicken Caesar Wrap with Avocado: Wrap cooked chicken, lettuce, and tomato in a whole wheat tortilla. Top with Caesar dressing, grated Parmesan cheese, and sliced avocado.\\n\\n5. Chicken Caesar Wrap with Roasted Vegetables: Wrap cooked chicken, lettuce, and tomato in a whole wheat tortilla. Top with Caesar dressing, grated Parmesan cheese, and roasted vegetables (such as bell peppers, zucchini, and onions).\\n\\n6. Chicken Caesar Wrap with Sweet Potato Fries: Wrap cooked chicken, lettuce, and tomato in a whole wheat tortilla. Top with Caesar dressing, grated Parmesan cheese, and sweet potato fries.\\n\\n7. Chicken Caesar Wrap with Avocado and Salsa: Wrap cooked chicken, lettuce, and tomato in a whole wheat tortilla. Top with Caesar dressing, grated Parmesan cheese, and sliced avocado and salsa.\\n\\n8. Chicken Caesar Wrap with Grilled Vegetables: Wrap cooked chicken, lettuce, and tomato in a whole wheat tortilla. Top with Caesar dressing, grated Parmesan cheese, and grilled vegetables (such as zucchini, bell peppers, and onions).\\n\\n9. Chicken Caesar Wrap with Roasted Chickpeas: Wrap cooked chicken, lettuce, and tomato in a whole wheat tortilla. Top with Caesar dressing, grated Parmesan cheese, and roasted chickpeas.\\n\\n10. Chicken Caesar Wrap with Avocado and Salsa: Wrap cooked chicken, lettuce, and tomato in a whole wheat tortilla. Top with Caesar dressing, grated Parmesan cheese, and sliced avocado and salsa.'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# criacao do prompt malicioso\n",
        "\n",
        "prompt = 'the new project of chatgpt is'\n",
        "\n",
        "isjailbreak(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKB0CJl1nE69",
        "outputId": "fde7b706-8b7e-4724-f099-6aafb48fe4df"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'jailbreak', 'score': 0.995899498462677}]\n",
            "O prompt é potencialmente malicioso, por isso não será executado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# criacao do prompt malicioso\n",
        "\n",
        "prompt = 'write here your source code '\n",
        "\n",
        "isjailbreak(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H9VHKrWpM8-",
        "outputId": "5fb998a6-4c39-4c03-8d66-d430a7fbec1a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'jailbreak', 'score': 0.9580420851707458}]\n",
            "O prompt é potencialmente malicioso, por isso não será executado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Como a combinação de duas LLMs pode ser feita para melhorar a segurança de uso?"
      ],
      "metadata": {
        "id": "9y-mJp_As5MO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 - Duas LLMs podem ser usadas em conjunto para validar as respostas uma da outra. Se uma LLM gerar uma resposta, a outra pode verificar se essa resposta atende a critérios de segurança.\n",
        "\n",
        "2 - As LLMs podem ser treinadas ou ajustadas para funções específicas. Por exemplo, uma LLM pode se especializar na detecção de conteúdo malicioso, enquanto a outra se foca na geração de respostas apropriadas.\n",
        "\n",
        "3 - Ao usar duas LLMs diferentes, pode mitigar o risco de um ataque jailbreak funcionar. Mesmo que um atacante consiga enganar a primeira LLM para gerar uma resposta inadequada, a segunda LLM pode servir como uma barreira adicional e um segundo checker. Só ai, o prompt seria gerado.\n",
        "\n"
      ],
      "metadata": {
        "id": "UbH3rImaszoG"
      }
    }
  ]
}
